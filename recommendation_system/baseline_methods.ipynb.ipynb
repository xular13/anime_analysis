{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-User Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import normalize\n",
    "import hnswlib\n",
    "from joblib import Parallel, delayed\n",
    "import optuna\n",
    "\n",
    "# --- Logging Configuration ---\n",
    "class FlushStreamHandler(logging.StreamHandler):\n",
    "    def emit(self, record):\n",
    "        try:\n",
    "            msg = self.format(record)\n",
    "            stream = self.stream\n",
    "            stream.write(msg + self.terminator)\n",
    "            self.flush()\n",
    "        except Exception:\n",
    "            self.handleError(record)\n",
    "\n",
    "LOG_FILENAME = \"debug.log\"\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "formatter = logging.Formatter(\"%(asctime)s %(levelname)s: %(message)s\")\n",
    "stream_handler = FlushStreamHandler(sys.stdout)\n",
    "stream_handler.setLevel(logging.INFO)\n",
    "stream_handler.setFormatter(formatter)\n",
    "file_handler = logging.FileHandler(LOG_FILENAME, mode=\"w\")\n",
    "file_handler.setLevel(logging.INFO)\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)\n",
    "logger.addHandler(file_handler)\n",
    "logger.info(\"Logging configured to INFO level with immediate flushing.\")\n",
    "\n",
    "# --- Global Settings ---\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "RELEVANCE_THRESHOLD = 7.0    # For ranking evaluation\n",
    "RANKING_SAMPLE_FRACTION = 0.2  # Evaluate ranking metrics on 20% of test users\n",
    "CACHE_DIR = \"cache\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "TOP_N = 10  # Top-N recommendations\n",
    "\n",
    "# --- Caching Helper Functions ---\n",
    "def cache_path(filename):\n",
    "    return os.path.join(CACHE_DIR, filename)\n",
    "\n",
    "def save_cache(obj, filename):\n",
    "    with open(cache_path(filename), \"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "    logger.info(f\"Saved cache to {cache_path(filename)}\")\n",
    "\n",
    "def load_cache(filename):\n",
    "    with open(cache_path(filename), \"rb\") as f:\n",
    "        obj = pickle.load(f)\n",
    "    logger.info(f\"Loaded cache from {cache_path(filename)}\")\n",
    "    return obj\n",
    "\n",
    "# --- Data Loading and Preprocessing ---\n",
    "def load_ratings(file_path):\n",
    "    logger.info(f\"Loading ratings from {file_path} ...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    logger.info(f\"Ratings shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "def load_anime_details(file_path):\n",
    "    logger.info(f\"Loading anime details from {file_path} ...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    logger.info(f\"Anime details shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "def build_rating_matrix(ratings_df):\n",
    "    cache_file = \"rating_matrix.pkl\"\n",
    "    if os.path.exists(cache_path(cache_file)):\n",
    "        rating_matrix = load_cache(cache_file)\n",
    "    else:\n",
    "        logger.info(\"Building rating matrix ...\")\n",
    "        rating_matrix = ratings_df.pivot(index='user_id', columns='anime_id', values='score')\n",
    "        rating_matrix = rating_matrix.fillna(0).astype(np.float32)\n",
    "        save_cache(rating_matrix, cache_file)\n",
    "    logger.info(f\"Rating matrix shape: {rating_matrix.shape}\")\n",
    "    return rating_matrix\n",
    "\n",
    "# --- Dimensionality Reduction and SVD Caching ---\n",
    "def reduce_dimensionality(rating_matrix, n_components):\n",
    "    cache_latent = f\"latent_matrix_{n_components}.pkl\"\n",
    "    cache_svd = f\"svd_model_{n_components}.pkl\"\n",
    "    if os.path.exists(cache_path(cache_latent)) and os.path.exists(cache_path(cache_svd)):\n",
    "        latent_matrix = load_cache(cache_latent)\n",
    "        svd_model = load_cache(cache_svd)\n",
    "    else:\n",
    "        logger.info(f\"Performing dimensionality reduction using TruncatedSVD with {n_components} components ...\")\n",
    "        svd_model = TruncatedSVD(n_components=n_components, random_state=RANDOM_STATE)\n",
    "        latent_matrix = svd_model.fit_transform(rating_matrix.values)\n",
    "        latent_matrix = normalize(latent_matrix, norm='l2')\n",
    "        save_cache(latent_matrix, cache_latent)\n",
    "        save_cache(svd_model, cache_svd)\n",
    "    logger.info(f\"Latent matrix shape: {latent_matrix.shape}\")\n",
    "    return latent_matrix, svd_model\n",
    "\n",
    "# --- HNSW Index Construction with Caching ---\n",
    "def build_hnsw_index(latent_matrix, ef_construction, M, ef):\n",
    "    # Include n_components in filename to distinguish different latent spaces.\n",
    "    n_components = latent_matrix.shape[1]\n",
    "    index_file = cache_path(f\"hnsw_index_{n_components}_{ef_construction}_{ef}.bin\")\n",
    "    num_elements, dim = latent_matrix.shape\n",
    "    if os.path.exists(index_file):\n",
    "        logger.info(\"Loading existing HNSW index from cache ...\")\n",
    "        index = hnswlib.Index(space='cosine', dim=dim)\n",
    "        index.init_index(max_elements=num_elements, ef_construction=ef_construction, M=M)\n",
    "        index.load_index(index_file)\n",
    "        index.set_ef(ef)\n",
    "    else:\n",
    "        logger.info(\"Building new HNSW index ...\")\n",
    "        index = hnswlib.Index(space='cosine', dim=dim)\n",
    "        index.init_index(max_elements=num_elements, ef_construction=ef_construction, M=M)\n",
    "        index.add_items(latent_matrix)\n",
    "        index.set_ef(ef)\n",
    "        index.save_index(index_file)\n",
    "        logger.info(f\"HNSW index saved to {index_file}\")\n",
    "    return index\n",
    "\n",
    "# --- Prediction Functions Using ANN (Existing Users) ---\n",
    "def predict_rating_approx(user_idx, rating_matrix, latent_matrix, hnsw_index, target_item, global_mean, k_neighbors):\n",
    "    query = latent_matrix[user_idx].reshape(1, -1)\n",
    "    neighbor_ids, distances = hnsw_index.knn_query(query, k=k_neighbors)\n",
    "    neighbor_ids = neighbor_ids[0]\n",
    "    distances = distances[0]\n",
    "    similarities = 1 - distances\n",
    "    training_matrix = rating_matrix.values\n",
    "    neighbor_ratings = training_matrix[neighbor_ids, target_item]\n",
    "    mask = neighbor_ratings != 0\n",
    "    if np.sum(mask) == 0:\n",
    "        return global_mean\n",
    "    valid_similarities = similarities[mask]\n",
    "    valid_ratings = neighbor_ratings[mask]\n",
    "    if np.sum(np.abs(valid_similarities)) == 0:\n",
    "        return global_mean\n",
    "    pred = np.dot(valid_similarities, valid_ratings) / np.sum(np.abs(valid_similarities))\n",
    "    return pred\n",
    "\n",
    "def get_top_n_recommendations_approx(user_idx, rating_matrix, latent_matrix, hnsw_index, anime_ids, global_mean, k_neighbors, top_n):\n",
    "    user_ratings = rating_matrix.values[user_idx]\n",
    "    predictions = {}\n",
    "    total_items = len(anime_ids)\n",
    "    for j, anime in enumerate(anime_ids):\n",
    "        if j % 100 == 0:\n",
    "            logger.info(f\"User {user_idx}: processed {j}/{total_items} items\")\n",
    "        if user_ratings[j] == 0:\n",
    "            pred = predict_rating_approx(user_idx, rating_matrix, latent_matrix, hnsw_index, j, global_mean, k_neighbors)\n",
    "            predictions[anime] = pred\n",
    "    top_n_recs = sorted(predictions.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    return top_n_recs\n",
    "\n",
    "# --- New User Recommendation Functions ---\n",
    "def build_new_user_vector(new_user_df, anime_ids):\n",
    "    new_user_vector = np.zeros(len(anime_ids), dtype=np.float32)\n",
    "    for idx, anime in enumerate(anime_ids):\n",
    "        if anime in new_user_df['anime_id'].values:\n",
    "            new_user_vector[idx] = new_user_df[new_user_df['anime_id'] == anime]['score'].values[0]\n",
    "    return new_user_vector\n",
    "\n",
    "def predict_rating_new_user_approx(new_user_vector, rating_matrix, latent_matrix, hnsw_index, target_item, global_mean, k_neighbors):\n",
    "    norm = np.linalg.norm(new_user_vector) + 1e-10\n",
    "    new_user_normed = new_user_vector / norm\n",
    "    query = new_user_normed.reshape(1, -1)\n",
    "    neighbor_ids, distances = hnsw_index.knn_query(query, k=k_neighbors)\n",
    "    neighbor_ids = neighbor_ids[0]\n",
    "    distances = distances[0]\n",
    "    similarities = 1 - distances\n",
    "    training_matrix = rating_matrix.values\n",
    "    neighbor_ratings = training_matrix[neighbor_ids, target_item]\n",
    "    mask = neighbor_ratings != 0\n",
    "    if np.sum(mask) == 0:\n",
    "        return global_mean\n",
    "    valid_similarities = similarities[mask]\n",
    "    valid_ratings = neighbor_ratings[mask]\n",
    "    if np.sum(np.abs(valid_similarities)) == 0:\n",
    "        return global_mean\n",
    "    pred = np.dot(valid_similarities, valid_ratings) / np.sum(np.abs(valid_similarities))\n",
    "    return pred\n",
    "\n",
    "def recommend_new_user_approx(new_user_df, model, top_n, k_neighbors):\n",
    "    anime_ids = model['anime_ids']\n",
    "    rating_matrix = model['rating_matrix']\n",
    "    global_mean = model['global_mean']\n",
    "    svd_model = model['svd_model']\n",
    "    \n",
    "    new_user_vector = build_new_user_vector(new_user_df, anime_ids)\n",
    "    new_user_latent = svd_model.transform(new_user_vector.reshape(1, -1))\n",
    "    new_user_latent = normalize(new_user_latent, norm='l2')\n",
    "    \n",
    "    hnsw_index = model['hnsw_index']\n",
    "    predictions = {}\n",
    "    for idx, anime in enumerate(anime_ids):\n",
    "        if new_user_vector[idx] == 0:\n",
    "            pred = predict_rating_new_user_approx(new_user_vector, rating_matrix, model['latent_matrix'], hnsw_index, idx, global_mean, k_neighbors)\n",
    "            predictions[anime] = pred\n",
    "    top_n_recs = sorted(predictions.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    return top_n_recs\n",
    "\n",
    "# --- Recommendation Enrichment Function ---\n",
    "def enrich_recommendations(recommendations, anime_details_df):\n",
    "    recs_df = pd.DataFrame(recommendations, columns=[\"anime_id\", \"predicted_rating\"])\n",
    "    enriched = pd.merge(recs_df, anime_details_df[['id', 'title', 'english_title']],\n",
    "                        left_on='anime_id', right_on='id', how='left')\n",
    "    enriched = enriched.drop(columns=['id'])\n",
    "    return enriched\n",
    "\n",
    "# --- Evaluation Metric Functions ---\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred)) ** 2))\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return np.mean(np.abs(np.array(y_true) - np.array(y_pred)))\n",
    "\n",
    "def precision_at_k(recommended, relevant, k=10):\n",
    "    recommended_k = [rec for rec, _ in recommended][:k]\n",
    "    if not recommended_k:\n",
    "        return 0.0\n",
    "    hits = len(set(recommended_k) & relevant)\n",
    "    return hits / k\n",
    "\n",
    "def recall_at_k(recommended, relevant, k=10):\n",
    "    recommended_k = [rec for rec, _ in recommended][:k]\n",
    "    if len(relevant) == 0:\n",
    "        return 0.0\n",
    "    hits = len(set(recommended_k) & relevant)\n",
    "    return hits / len(relevant)\n",
    "\n",
    "def ndcg_at_k(recommended, relevant, k=10):\n",
    "    dcg = 0.0\n",
    "    for i, (rec, _) in enumerate(recommended[:k]):\n",
    "        if rec in relevant:\n",
    "            dcg += 1 / np.log2(i + 2)\n",
    "    ideal_hits = min(len(relevant), k)\n",
    "    idcg = sum(1 / np.log2(i + 2) for i in range(ideal_hits))\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "# --- Parallel Ranking Metrics Evaluation Function ---\n",
    "def compute_ranking_metrics_for_user(user, group, rating_matrix, latent_matrix, hnsw_index, anime_ids, global_mean, k_neighbors, top_n, relevance_threshold):\n",
    "    if user not in rating_matrix.index:\n",
    "        return None\n",
    "    relevant_items = set(group[group['score'] >= relevance_threshold]['anime_id'])\n",
    "    if not relevant_items:\n",
    "        return None\n",
    "    user_idx = np.where(rating_matrix.index == user)[0][0]\n",
    "    recs = get_top_n_recommendations_approx(user_idx, rating_matrix, latent_matrix, hnsw_index, anime_ids, global_mean, k_neighbors, top_n)\n",
    "    prec = precision_at_k(recs, relevant_items, k=top_n)\n",
    "    rec = recall_at_k(recs, relevant_items, k=top_n)\n",
    "    ndcg_val = ndcg_at_k(recs, relevant_items, k=top_n)\n",
    "    return prec, rec, ndcg_val\n",
    "\n",
    "# --- Function to Run a Single Experiment ---\n",
    "def run_experiment(params, train_df, test_df, rating_matrix):\n",
    "    global_mean = train_df['score'].mean()\n",
    "    latent_matrix, svd_model = reduce_dimensionality(rating_matrix, n_components=params[\"svd_n_components\"])\n",
    "    hnsw_index = build_hnsw_index(latent_matrix, ef_construction=params[\"hnsw_ef_construction\"], M=HNSW_M, ef=params[\"hnsw_ef\"])\n",
    "    \n",
    "    # Evaluate pointwise metrics.\n",
    "    y_true, y_pred = [], []\n",
    "    for i, (_, row) in enumerate(test_df.iterrows(), start=1):\n",
    "        user = row['user_id']\n",
    "        anime = row['anime_id']\n",
    "        true_score = float(row['score'])\n",
    "        if user in rating_matrix.index and anime in rating_matrix.columns:\n",
    "            user_idx = np.where(rating_matrix.index == user)[0][0]\n",
    "            item_idx = np.where(rating_matrix.columns == anime)[0][0]\n",
    "            pred_score = predict_rating_approx(user_idx, rating_matrix, latent_matrix, hnsw_index, item_idx, global_mean, k_neighbors=params[\"k_neighbors\"])\n",
    "            y_true.append(true_score)\n",
    "            y_pred.append(pred_score)\n",
    "    rmse_val = rmse(y_true, y_pred) if y_true else None\n",
    "    mae_val = mae(y_true, y_pred) if y_true else None\n",
    "    \n",
    "    # Evaluate ranking metrics on a sample of test users.\n",
    "    test_groups = list(test_df.groupby('user_id'))\n",
    "    np.random.shuffle(test_groups)\n",
    "    sample_size = int(len(test_groups) * RANKING_SAMPLE_FRACTION)\n",
    "    sampled_groups = test_groups[:sample_size]\n",
    "    results = Parallel(n_jobs=-1)(delayed(compute_ranking_metrics_for_user)(\n",
    "        user, group, rating_matrix, latent_matrix, hnsw_index, rating_matrix.columns.values, global_mean,\n",
    "        params[\"k_neighbors\"], TOP_N, RELEVANCE_THRESHOLD\n",
    "    ) for user, group in sampled_groups)\n",
    "    valid_results = [res for res in results if res is not None]\n",
    "    if valid_results:\n",
    "        precisions, recalls, ndcgs = zip(*valid_results)\n",
    "        precision_val = np.mean(precisions)\n",
    "        recall_val = np.mean(recalls)\n",
    "        ndcg_val = np.mean(ndcgs)\n",
    "    else:\n",
    "        precision_val = recall_val = ndcg_val = None\n",
    "        \n",
    "    metrics = {\"rmse\": rmse_val, \"mae\": mae_val, \"precision_at_10\": precision_val,\n",
    "               \"recall_at_10\": recall_val, \"ndcg_at_10\": ndcg_val}\n",
    "    return metrics, latent_matrix, svd_model, hnsw_index\n",
    "\n",
    "# --- Hyperparameter Optimization with Optuna ---\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters.\n",
    "    svd_n_components = trial.suggest_categorical(\"svd_n_components\", [50, 100, 200, 250, 300])\n",
    "    k_neighbors = trial.suggest_categorical(\"k_neighbors\", [15, 20, 30, 50])\n",
    "    hnsw_ef = trial.suggest_categorical(\"hnsw_ef\", [50, 100, 150])\n",
    "    hnsw_ef_construction = trial.suggest_categorical(\"hnsw_ef_construction\", [100, 200, 300])\n",
    "    \n",
    "    params = {\n",
    "        \"svd_n_components\": svd_n_components,\n",
    "        \"k_neighbors\": k_neighbors,\n",
    "        \"hnsw_ef\": hnsw_ef,\n",
    "        \"hnsw_ef_construction\": hnsw_ef_construction\n",
    "    }\n",
    "    logger.info(f\"Trial with parameters: {params}\")\n",
    "    \n",
    "    # Load ratings and split data.\n",
    "    ratings_file = \"data_new/animelist.csv\"\n",
    "    ratings_df = load_ratings(ratings_file)\n",
    "    train_df, test_df = train_test_split(ratings_df, test_size=0.2, random_state=RANDOM_STATE)\n",
    "    rating_matrix = build_rating_matrix(train_df)\n",
    "    \n",
    "    try:\n",
    "        metrics, latent_matrix, svd_model, hnsw_index = run_experiment(params, train_df, test_df, rating_matrix)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in trial: {e}\")\n",
    "        return float('inf')\n",
    "    \n",
    "    # Record additional metrics as user attributes.\n",
    "    trial.set_user_attr(\"mae\", metrics[\"mae\"])\n",
    "    trial.set_user_attr(\"precision_at_10\", metrics[\"precision_at_10\"])\n",
    "    trial.set_user_attr(\"recall_at_10\", metrics[\"recall_at_10\"])\n",
    "    trial.set_user_attr(\"ndcg_at_10\", metrics[\"ndcg_at_10\"])\n",
    "    \n",
    "    if metrics[\"rmse\"] is None:\n",
    "        return float('inf')\n",
    "    logger.info(f\"Trial metrics: {metrics}\")\n",
    "    return metrics[\"rmse\"]\n",
    "\n",
    "def main_experiment():\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=20)  # Adjust number of trials as needed.\n",
    "    \n",
    "    # Save study results to CSV.\n",
    "    results = []\n",
    "    for trial in study.trials:\n",
    "        results.append({\n",
    "            \"model_name\": \"UserUser_ANN\",\n",
    "            \"rmse\": trial.value,\n",
    "            \"mae\": trial.user_attrs.get(\"mae\"),\n",
    "            \"precision_at_10\": trial.user_attrs.get(\"precision_at_10\"),\n",
    "            \"recall_at_10\": trial.user_attrs.get(\"recall_at_10\"),\n",
    "            \"ndcg_at_10\": trial.user_attrs.get(\"ndcg_at_10\"),\n",
    "            \"parameters\": str(trial.params)\n",
    "        })\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_csv = \"experiment_results.csv\"\n",
    "    results_df.to_csv(results_csv, index=False)\n",
    "    logger.info(f\"Saved experiment results to {results_csv}\")\n",
    "    logger.info(f\"Best trial: {study.best_trial.params} with RMSE: {study.best_trial.value}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_for_new_user():\n",
    "    #Generate recommendations for a new user.\n",
    "    # Uncomment and adjust if you have new user data.\n",
    "    MODEL = 'models/user_user_cf_model_approx.pkl'\n",
    "    new_user_df = load_ratings(\"data_new/user_data.csv\")\n",
    "    anime_details_df = pd.read_csv('data_new/anime_details_v1.csv')\n",
    "    with open(MODEL, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "        logger.info(f\"Loaded cache from {cache_path(MODEL)}\")\n",
    "    new_user_recs = recommend_new_user_approx(new_user_df, model, top_n=10, k_neighbors=30)\n",
    "    enriched_new_user_recs = enrich_recommendations(new_user_recs, anime_details_df)\n",
    "    logger.info(\"Top-10 recommendations for new user:\")\n",
    "    logger.info(f\"\\n{enriched_new_user_recs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_for_new_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import Parallel, delayed\n",
    "import optuna\n",
    "\n",
    "# --- Logging Configuration ---\n",
    "class FlushStreamHandler(logging.StreamHandler):\n",
    "    def emit(self, record):\n",
    "        try:\n",
    "            msg = self.format(record)\n",
    "            self.stream.write(msg + self.terminator)\n",
    "            self.flush()\n",
    "        except Exception:\n",
    "            self.handleError(record)\n",
    "\n",
    "LOG_FILENAME = \"mf_debug.log\"\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "formatter = logging.Formatter(\"%(asctime)s %(levelname)s: %(message)s\")\n",
    "stream_handler = FlushStreamHandler(sys.stdout)\n",
    "stream_handler.setLevel(logging.INFO)\n",
    "stream_handler.setFormatter(formatter)\n",
    "file_handler = logging.FileHandler(LOG_FILENAME, mode=\"w\")\n",
    "file_handler.setLevel(logging.INFO)\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)\n",
    "logger.addHandler(file_handler)\n",
    "logger.info(\"Logging configured to INFO level with immediate flushing.\")\n",
    "\n",
    "# --- Global Settings ---\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "TRAIN_TEST_SPLIT = 0.2\n",
    "MODEL_SAVE_PATH = \"models/mf_best_model.pkl\"\n",
    "RELEVANCE_THRESHOLD = 7.0       # For ranking evaluation\n",
    "RANKING_SAMPLE_FRACTION = 0.2   # Evaluate ranking metrics on 20% of test users\n",
    "TOP_N = 10                    # Top-N recommendations\n",
    "CACHE_DIR = \"cache\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# --- Hyperparameter Grid for Optuna ---\n",
    "# (These will be suggested by Optuna.)\n",
    "# We'll tune: n_factors, learning_rate, regularization, and n_epochs.\n",
    "\n",
    "# --- Caching Helper Functions ---\n",
    "def cache_path(filename):\n",
    "    return os.path.join(CACHE_DIR, filename)\n",
    "\n",
    "def save_cache(obj, filename):\n",
    "    with open(cache_path(filename), \"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "    logger.info(f\"Saved cache to {cache_path(filename)}\")\n",
    "\n",
    "def load_cache(filename):\n",
    "    with open(cache_path(filename), \"rb\") as f:\n",
    "        obj = pickle.load(f)\n",
    "    logger.info(f\"Loaded cache from {cache_path(filename)}\")\n",
    "    return obj\n",
    "\n",
    "# --- Data Loading Functions ---\n",
    "def load_ratings(file_path):\n",
    "    logger.info(f\"Loading ratings from {file_path} ...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    logger.info(f\"Ratings shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "def load_anime_details(file_path):\n",
    "    logger.info(f\"Loading anime details from {file_path} ...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    logger.info(f\"Anime details shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "def build_rating_matrix(ratings_df):\n",
    "    logger.info(\"Building rating matrix ...\")\n",
    "    rating_matrix = ratings_df.pivot(index='user_id', columns='anime_id', values='score')\n",
    "    rating_matrix = rating_matrix.fillna(0).astype(np.float32)\n",
    "    logger.info(f\"Rating matrix shape: {rating_matrix.shape}\")\n",
    "    return rating_matrix\n",
    "\n",
    "# --- Matrix Factorization Functions ---\n",
    "def initialize_factors(n_users, n_items, n_factors):\n",
    "    U = np.random.normal(scale=0.1, size=(n_users, n_factors))\n",
    "    V = np.random.normal(scale=0.1, size=(n_items, n_factors))\n",
    "    return U, V\n",
    "\n",
    "def train_matrix_factorization(rating_matrix, n_factors, learning_rate, reg, n_epochs):\n",
    "    R = rating_matrix.values\n",
    "    n_users, n_items = R.shape\n",
    "    U, V = initialize_factors(n_users, n_items, n_factors)\n",
    "    observed = R > 0\n",
    "\n",
    "    logger.info(\"Starting training matrix factorization ...\")\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0.0\n",
    "        for u in range(n_users):\n",
    "            for i in range(n_items):\n",
    "                if observed[u, i]:\n",
    "                    pred = np.dot(U[u], V[i])\n",
    "                    error = R[u, i] - pred\n",
    "                    total_loss += error ** 2\n",
    "                    U[u] += learning_rate * (error * V[i] - reg * U[u])\n",
    "                    V[i] += learning_rate * (error * U[u] - reg * V[i])\n",
    "        rmse_epoch = np.sqrt(total_loss / observed.sum())\n",
    "        logger.info(f\"Epoch {epoch+1}/{n_epochs} - Training RMSE: {rmse_epoch:.4f}\")\n",
    "    return U, V\n",
    "\n",
    "def predict_rating(u, i, U, V):\n",
    "    return np.dot(U[u], V[i])\n",
    "\n",
    "def evaluate_model(rating_matrix, U, V, test_df):\n",
    "    R = rating_matrix.values\n",
    "    y_true, y_pred = [], []\n",
    "    for idx, row in test_df.iterrows():\n",
    "        user = row['user_id']\n",
    "        anime = row['anime_id']\n",
    "        true_rating = float(row['score'])\n",
    "        if user in rating_matrix.index and anime in rating_matrix.columns:\n",
    "            u_idx = np.where(rating_matrix.index == user)[0][0]\n",
    "            i_idx = np.where(rating_matrix.columns == anime)[0][0]\n",
    "            pred = predict_rating(u_idx, i_idx, U, V)\n",
    "            y_true.append(true_rating)\n",
    "            y_pred.append(pred)\n",
    "    rmse_val = np.sqrt(np.mean((np.array(y_true) - np.array(y_pred)) ** 2))\n",
    "    mae_val = np.mean(np.abs(np.array(y_true) - np.array(y_pred)))\n",
    "    return rmse_val, mae_val\n",
    "\n",
    "def get_top_n_recommendations(u_idx, rating_matrix, U, V, top_n=10):\n",
    "    R = rating_matrix.values\n",
    "    user_ratings = R[u_idx]\n",
    "    predictions = {}\n",
    "    for i, _ in enumerate(user_ratings):\n",
    "        if user_ratings[i] == 0:\n",
    "            pred = predict_rating(u_idx, i, U, V)\n",
    "            predictions[rating_matrix.columns[i]] = pred\n",
    "    top_n_recs = sorted(predictions.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    return top_n_recs\n",
    "\n",
    "# --- Ranking Metrics Functions ---\n",
    "def precision_at_k(recommended, relevant, k=10):\n",
    "    recommended_k = [rec for rec, _ in recommended][:k]\n",
    "    if not recommended_k:\n",
    "        return 0.0\n",
    "    hits = len(set(recommended_k) & relevant)\n",
    "    return hits / k\n",
    "\n",
    "def recall_at_k(recommended, relevant, k=10):\n",
    "    recommended_k = [rec for rec, _ in recommended][:k]\n",
    "    if len(relevant) == 0:\n",
    "        return 0.0\n",
    "    hits = len(set(recommended_k) & relevant)\n",
    "    return hits / len(relevant)\n",
    "\n",
    "def ndcg_at_k(recommended, relevant, k=10):\n",
    "    dcg = 0.0\n",
    "    for i, (rec, _) in enumerate(recommended[:k]):\n",
    "        if rec in relevant:\n",
    "            dcg += 1 / np.log2(i + 2)\n",
    "    ideal_hits = min(len(relevant), k)\n",
    "    idcg = sum(1 / np.log2(i + 2) for i in range(ideal_hits))\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "def compute_ranking_metrics_for_user_mf(user, group, rating_matrix, U, V, anime_ids, top_n, relevance_threshold):\n",
    "    if user not in rating_matrix.index:\n",
    "        return None\n",
    "    relevant_items = set(group[group['score'] >= relevance_threshold]['anime_id'])\n",
    "    if not relevant_items:\n",
    "        return None\n",
    "    u_idx = np.where(rating_matrix.index == user)[0][0]\n",
    "    recs = get_top_n_recommendations(u_idx, rating_matrix, U, V, top_n)\n",
    "    prec = precision_at_k(recs, relevant_items, k=top_n)\n",
    "    rec = recall_at_k(recs, relevant_items, k=top_n)\n",
    "    ndcg_val = ndcg_at_k(recs, relevant_items, k=top_n)\n",
    "    return prec, rec, ndcg_val\n",
    "\n",
    "# --- New User \"Fold-In\" Functions for MF ---\n",
    "def fold_in_new_user(new_user_vector, V, learning_rate=0.005, reg=0.02, n_iter=50):\n",
    "    \"\"\"\n",
    "    Given a new user's rating vector (length = n_items, with zeros for missing ratings)\n",
    "    and the trained item latent factor matrix V (shape: n_items x n_factors),\n",
    "    optimize a user latent vector u_new that minimizes:\n",
    "       sum_{i: observed} (r[i] - u_new.dot(V[i]))^2 + reg * ||u_new||^2\n",
    "    using gradient descent.\n",
    "    Returns the new user's latent factor vector (1D NumPy array).\n",
    "    \"\"\"\n",
    "    n_factors = V.shape[1]\n",
    "    u_new = np.random.normal(scale=0.1, size=(n_factors,))\n",
    "    observed = new_user_vector > 0\n",
    "    for _ in range(n_iter):\n",
    "        pred = V[observed].dot(u_new)\n",
    "        error = new_user_vector[observed] - pred\n",
    "        grad = -2 * V[observed].T.dot(error) + 2 * reg * u_new\n",
    "        u_new = u_new - learning_rate * grad\n",
    "    return u_new\n",
    "\n",
    "def recommend_new_user_mf(new_user_df, model, n_iter=50, learning_rate=0.005, reg=0.02, top_n=TOP_N):\n",
    "    \"\"\"\n",
    "    Generate recommendations for a new user by \"folding in\" the new user into the trained MF model.\n",
    "    The item latent factor matrix V from the model is used to compute the new user's latent vector.\n",
    "    \"\"\"\n",
    "    anime_ids = model['rating_matrix'].columns.values\n",
    "    rating_matrix = model['rating_matrix']\n",
    "    V = model['V']\n",
    "    global_mean = model['global_mean']\n",
    "    \n",
    "    new_user_vector = np.zeros(len(anime_ids), dtype=np.float32)\n",
    "    for idx, anime in enumerate(anime_ids):\n",
    "        if anime in new_user_df['anime_id'].values:\n",
    "            new_user_vector[idx] = new_user_df[new_user_df['anime_id'] == anime]['score'].values[0]\n",
    "    \n",
    "    u_new = fold_in_new_user(new_user_vector, V, learning_rate, reg, n_iter)\n",
    "    \n",
    "    # Predict ratings for all items not rated by the new user.\n",
    "    predictions = {}\n",
    "    for i, anime in enumerate(anime_ids):\n",
    "        if new_user_vector[i] == 0:\n",
    "            pred = np.dot(u_new, V[i])\n",
    "            predictions[anime] = pred\n",
    "    top_n_recs = sorted(predictions.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    return top_n_recs\n",
    "\n",
    "# --- Experiment Function for MF ---\n",
    "def run_mf_experiment(params, train_df, test_df, rating_matrix):\n",
    "    U, V = train_matrix_factorization(\n",
    "        rating_matrix, \n",
    "        n_factors=params[\"n_factors\"],\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        reg=params[\"reg\"],\n",
    "        n_epochs=params[\"n_epochs\"]\n",
    "    )\n",
    "    rmse_val, mae_val = evaluate_model(rating_matrix, U, V, test_df)\n",
    "    \n",
    "    # Evaluate ranking metrics on a sample of test users.\n",
    "    test_groups = list(test_df.groupby('user_id'))\n",
    "    np.random.shuffle(test_groups)\n",
    "    sample_size = int(len(test_groups) * RANKING_SAMPLE_FRACTION)\n",
    "    sampled_groups = test_groups[:sample_size]\n",
    "    results = Parallel(n_jobs=-1)(delayed(compute_ranking_metrics_for_user_mf)(\n",
    "        user, group, rating_matrix, U, V, rating_matrix.columns.values, TOP_N, RELEVANCE_THRESHOLD\n",
    "    ) for user, group in sampled_groups)\n",
    "    valid_results = [res for res in results if res is not None]\n",
    "    if valid_results:\n",
    "        precisions, recalls, ndcgs = zip(*valid_results)\n",
    "        precision_val = np.mean(precisions)\n",
    "        recall_val = np.mean(recalls)\n",
    "        ndcg_val = np.mean(ndcgs)\n",
    "    else:\n",
    "        precision_val = recall_val = ndcg_val = None\n",
    "    \n",
    "    metrics = {\"rmse\": rmse_val, \"mae\": mae_val, \"precision_at_10\": precision_val,\n",
    "               \"recall_at_10\": recall_val, \"ndcg_at_10\": ndcg_val}\n",
    "    return metrics, U, V\n",
    "\n",
    "# --- Optuna Objective Function for MF ---\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters.\n",
    "    n_factors = trial.suggest_categorical(\"n_factors\", [50, 100, 150, 200])\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
    "    reg = trial.suggest_loguniform(\"reg\", 1e-3, 1e-1)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 20, 100)\n",
    "    \n",
    "    params = {\n",
    "        \"n_factors\": n_factors,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"reg\": reg,\n",
    "        \"n_epochs\": n_epochs\n",
    "    }\n",
    "    logger.info(f\"Trial with parameters: {params}\")\n",
    "    \n",
    "    ratings_file = \"data_new/animelist.csv\"\n",
    "    ratings_df = load_ratings(ratings_file)\n",
    "    train_df, test_df = train_test_split(ratings_df, test_size=TRAIN_TEST_SPLIT, random_state=RANDOM_STATE)\n",
    "    rating_matrix = build_rating_matrix(train_df)\n",
    "    \n",
    "    try:\n",
    "        metrics, U, V = run_mf_experiment(params, train_df, test_df, rating_matrix)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in trial: {e}\")\n",
    "        return float('inf')\n",
    "    \n",
    "    trial.set_user_attr(\"mae\", metrics[\"mae\"])\n",
    "    trial.set_user_attr(\"precision_at_10\", metrics[\"precision_at_10\"])\n",
    "    trial.set_user_attr(\"recall_at_10\", metrics[\"recall_at_10\"])\n",
    "    trial.set_user_attr(\"ndcg_at_10\", metrics[\"ndcg_at_10\"])\n",
    "    \n",
    "    if metrics[\"rmse\"] is None:\n",
    "        return float('inf')\n",
    "    logger.info(f\"Trial metrics: {metrics}\")\n",
    "    return metrics[\"rmse\"]\n",
    "\n",
    "def main_experiment():\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=20)\n",
    "    \n",
    "    # Save study results to CSV.\n",
    "    results = []\n",
    "    for trial in study.trials:\n",
    "        results.append({\n",
    "            \"model_name\": \"MF_SGD\",\n",
    "            \"rmse\": trial.value,\n",
    "            \"mae\": trial.user_attrs.get(\"mae\"),\n",
    "            \"precision_at_10\": trial.user_attrs.get(\"precision_at_10\"),\n",
    "            \"recall_at_10\": trial.user_attrs.get(\"recall_at_10\"),\n",
    "            \"ndcg_at_10\": trial.user_attrs.get(\"ndcg_at_10\"),\n",
    "            \"parameters\": str(trial.params)\n",
    "        })\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_csv = \"mf_experiment_results.csv\"\n",
    "    results_df.to_csv(results_csv, index=False)\n",
    "    logger.info(f\"Saved experiment results to {results_csv}\")\n",
    "    logger.info(f\"Best trial: {study.best_trial.params} with RMSE: {study.best_trial.value}\")\n",
    "    \n",
    "    # Train the best model on the full training data and save it.\n",
    "    best_params = study.best_trial.params\n",
    "    ratings_file = \"data_new/animelist.csv\"\n",
    "    ratings_df = load_ratings(ratings_file)\n",
    "    # Split data into train and test sets (ensure test set is non-empty).\n",
    "    train_df, test_df = train_test_split(ratings_df, test_size=TRAIN_TEST_SPLIT, random_state=RANDOM_STATE)\n",
    "    logger.info(f\"Final training: Train shape: {train_df.shape}, Test shape: {test_df.shape}\")\n",
    "    \n",
    "    # Build the rating matrix from the training data.\n",
    "    rating_matrix = build_rating_matrix(train_df)\n",
    "\n",
    "    metrics, U, V = run_mf_experiment(best_params, train_df, pd.DataFrame(), rating_matrix)[0:3]\n",
    "    best_model = {\n",
    "        \"U\": U,\n",
    "        \"V\": V,\n",
    "        \"rating_matrix\": rating_matrix,\n",
    "        \"global_mean\": train_df['score'].mean()\n",
    "    }\n",
    "    with open(MODEL_SAVE_PATH, \"wb\") as f:\n",
    "        pickle.dump(best_model, f)\n",
    "    logger.info(f\"Best MF model saved to {MODEL_SAVE_PATH}\")\n",
    "    \n",
    "    # Example: New user recommendation using fold-in.\n",
    "    # If a new user rating file exists, load it and generate recommendations.\n",
    "    new_user_file = \"data_new/user_data.csv\"\n",
    "    if os.path.exists(new_user_file):\n",
    "        new_user_df = pd.read_csv(new_user_file)\n",
    "        # Use the fold-in procedure to compute new user latent factors.\n",
    "        new_user_vector = np.zeros(len(rating_matrix.columns), dtype=np.float32)\n",
    "        for idx, anime in enumerate(rating_matrix.columns):\n",
    "            if anime in new_user_df['anime_id'].values:\n",
    "                new_user_vector[idx] = new_user_df[new_user_df['anime_id'] == anime]['score'].values[0]\n",
    "        # Fold-in new user latent vector using item factors V.\n",
    "        def fold_in_new_user(new_user_vector, V, learning_rate=0.005, reg=0.02, n_iter=50):\n",
    "            n_factors = V.shape[1]\n",
    "            u_new = np.random.normal(scale=0.1, size=(n_factors,))\n",
    "            observed = new_user_vector > 0\n",
    "            for _ in range(n_iter):\n",
    "                pred = V[observed].dot(u_new)\n",
    "                error = new_user_vector[observed] - pred\n",
    "                grad = -2 * V[observed].T.dot(error) + 2 * reg * u_new\n",
    "                u_new = u_new - learning_rate * grad\n",
    "            return u_new\n",
    "        \n",
    "        u_new = fold_in_new_user(new_user_vector, best_model[\"V\"])\n",
    "        # Predict ratings for all items for new user.\n",
    "        predictions = {}\n",
    "        for i, anime in enumerate(rating_matrix.columns):\n",
    "            if new_user_vector[i] == 0:\n",
    "                pred = np.dot(u_new, best_model[\"V\"][i])\n",
    "                predictions[anime] = pred\n",
    "        new_user_recs = sorted(predictions.items(), key=lambda x: x[1], reverse=True)[:TOP_N]\n",
    "        logger.info(\"Top-10 recommendations for new user:\")\n",
    "        logger.info(new_user_recs)\n",
    "    else:\n",
    "        logger.info(\"No new user data found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ive got error on final retraining, but i have saved best params from our experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_model_training(best_params):\n",
    "    \"\"\"\n",
    "    Retrains the matrix factorization model on a proper train/test split using the best \n",
    "    hyperparameters from the previous study, and saves the final model to disk.\n",
    "    This function avoids passing an empty test DataFrame.\n",
    "    \"\"\"\n",
    "    # Load ratings from file.\n",
    "    ratings_file = \"data_new/animelist.csv\"  # Adjust path as needed.\n",
    "    ratings_df = load_ratings(ratings_file)\n",
    "    \n",
    "    # Split data into train and test sets (ensure test set is non-empty).\n",
    "    train_df, test_df = train_test_split(ratings_df, test_size=TRAIN_TEST_SPLIT, random_state=RANDOM_STATE)\n",
    "    logger.info(f\"Final training: Train shape: {train_df.shape}, Test shape: {test_df.shape}\")\n",
    "    \n",
    "    # Build the rating matrix from the training data.\n",
    "    rating_matrix = build_rating_matrix(train_df)\n",
    "    \n",
    "    # Optionally, if you prefer to train on the full data without evaluation,\n",
    "    # you could set test_df = train_df or perform another split.\n",
    "    \n",
    "    # Run the matrix factorization experiment (which includes evaluation) using best_params.\n",
    "    metrics, U, V = run_mf_experiment(best_params, train_df, test_df, rating_matrix)[0:3]\n",
    "    logger.info(f\"Final model training metrics: RMSE: {metrics['rmse']:.4f}, MAE: {metrics['mae']:.4f}\")\n",
    "    \n",
    "    # Build the final model dictionary.\n",
    "    best_model = {\n",
    "        \"U\": U,\n",
    "        \"V\": V,\n",
    "        \"rating_matrix\": rating_matrix,\n",
    "        \"global_mean\": train_df['score'].mean()\n",
    "    }\n",
    "    \n",
    "    # Save the final model.\n",
    "    with open(MODEL_SAVE_PATH, \"wb\") as f:\n",
    "        pickle.dump(best_model, f)\n",
    "    logger.info(f\"Best MF model saved to {MODEL_SAVE_PATH}\")\n",
    "    \n",
    "    # (Optional) Demonstrate new user recommendations using fold-in.\n",
    "    new_user_file = \"data_new/user_data.csv\"  # Adjust path if new user data exists.\n",
    "    if os.path.exists(new_user_file):\n",
    "        new_user_df = pd.read_csv(new_user_file)\n",
    "        u_new = fold_in_new_user(\n",
    "            new_user_vector=build_new_user_vector(new_user_df, rating_matrix.columns.values),\n",
    "            V=V,\n",
    "            learning_rate=best_params.get(\"learning_rate\", 0.005),\n",
    "            reg=best_params.get(\"reg\", 0.02),\n",
    "            n_iter=50  # You might tune this as well.\n",
    "        )\n",
    "        predictions = {}\n",
    "        for i, anime in enumerate(rating_matrix.columns):\n",
    "            if build_new_user_vector(new_user_df, rating_matrix.columns.values)[i] == 0:\n",
    "                predictions[anime] = np.dot(u_new, V[i])\n",
    "        new_user_recs = sorted(predictions.items(), key=lambda x: x[1], reverse=True)[:TOP_N]\n",
    "        logger.info(\"Top-10 recommendations for new user:\")\n",
    "        logger.info(new_user_recs)\n",
    "    else:\n",
    "        logger.info(\"No new user data found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main function to run final training (without re-running grid search) ---\n",
    "def main_final():\n",
    "    import ast\n",
    "    results = pd.read_csv('mf_experiment_results.csv')\n",
    "    best_params = ast.literal_eval(results[results['rmse']==results['rmse'].min()]['parameters'].iloc[0])\n",
    "    logger.info(f\"Using best parameters from study: {best_params}\")\n",
    "    final_model_training(best_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_final()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [(11061, 8.751748977151662), (38524, 8.742807908264286), (820, 8.714674665393), (5114, 8.712958329730348), (43608, 8.682679336936072), (9253, 8.681530886869453), (19, 8.622045115225914), (9969, 8.609232614843217), (24701, 8.587685704058096), (35247, 8.586207890504708)]\n",
    "anime_ids = []\n",
    "for elem in s:\n",
    "    anime_ids.append(elem[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_new/anime_details_v1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['id'].isin(anime_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WRMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "import implicit\n",
    "\n",
    "# --- Logging Configuration (real-time flush) ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s: %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# --- Global Settings & File Paths ---\n",
    "RANDOM_STATE = 42\n",
    "TRAIN_TEST_SPLIT = 0.2\n",
    "TOP_N = 10                   # top-10 recommendations\n",
    "ALPHA = 40                   # Confidence scaling: C = 1 + ALPHA * implicit_signal\n",
    "\n",
    "# Default hyperparameters for WRMF (to be tuned)\n",
    "DEFAULT_FACTORS = 50\n",
    "DEFAULT_REG = 0.01\n",
    "DEFAULT_ITER = 10\n",
    "\n",
    "# Data file paths\n",
    "ANIMELIST_FILE = \"data_new/animelist.csv\"            \n",
    "ANIME_DETAILS_FILE = \"data_new/anime_details_v1.csv\"   \n",
    "MODEL_SAVE_PATH = \"models/wrmf_best_model.pkl\"\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"cache\", exist_ok=True)\n",
    "\n",
    "# --- Caching Helper Functions ---\n",
    "def cache_path(filename):\n",
    "    return os.path.join(\"cache\", filename)\n",
    "\n",
    "def save_cache_obj(obj, filename):\n",
    "    with open(cache_path(filename), \"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "    logger.info(f\"Saved cache to {cache_path(filename)}\")\n",
    "\n",
    "def load_cache_obj(filename):\n",
    "    with open(cache_path(filename), \"rb\") as f:\n",
    "        obj = pickle.load(f)\n",
    "    logger.info(f\"Loaded cache from {cache_path(filename)}\")\n",
    "    return obj\n",
    "\n",
    "def cache_key(params):\n",
    "    return f\"wrmf_results_{params['factors']}_{params['reg']}_{params['n_iter']}_{params['alpha']}.pkl\"\n",
    "\n",
    "# --- Data Loading Functions ---\n",
    "def load_data(animelist_path, anime_details_path):\n",
    "    logger.info(\"Loading animelist from '%s'\", animelist_path)\n",
    "    animelist = pd.read_csv(animelist_path)\n",
    "    logger.info(\"Animelist shape: %s\", animelist.shape)\n",
    "    \n",
    "    logger.info(\"Loading anime details from '%s'\", anime_details_path)\n",
    "    anime_details = pd.read_csv(anime_details_path)\n",
    "    logger.info(\"Anime details shape: %s\", anime_details.shape)\n",
    "    \n",
    "    return animelist, anime_details\n",
    "\n",
    "# --- Preprocessing & Transformation ---\n",
    "def preprocess(animelist, anime_details):\n",
    "    logger.info(\"Preprocessing animelist data...\")\n",
    "    animelist['score'] = animelist['score'].fillna(0)\n",
    "    animelist['status'] = animelist['status'].str.lower()\n",
    "    \n",
    "    status_mapping = {\n",
    "        'completed': 1.0,\n",
    "        'on_hold': 0.5,\n",
    "        'plan_to_watch': 0.2,\n",
    "        'dropped': 0.0,\n",
    "        'watching': 0.8,\n",
    "        'rewatching': 0.9\n",
    "    }\n",
    "    logger.info(\"Mapping status using: %s\", status_mapping)\n",
    "    animelist['status_weight'] = animelist['status'].map(status_mapping)\n",
    "    missing = animelist['status_weight'].isna().sum()\n",
    "    if missing > 0:\n",
    "        logger.warning(\"Found %d missing status weights; filling with 0\", missing)\n",
    "        animelist['status_weight'] = animelist['status_weight'].fillna(0)\n",
    "    \n",
    "    logger.info(\"Renaming 'id' to 'anime_id' in anime details and merging\")\n",
    "    anime_details = anime_details.rename(columns={'id': 'anime_id'})\n",
    "    merged = pd.merge(animelist, anime_details[['anime_id', 'num_episodes']], on='anime_id', how='left')\n",
    "    merged['num_episodes'] = merged['num_episodes'].fillna(1)\n",
    "    logger.info(\"Computing episode ratio as num_episodes_watched/num_episodes\")\n",
    "    merged['episode_ratio'] = (merged['num_episodes_watched'] / merged['num_episodes']).clip(upper=1)\n",
    "    \n",
    "    logger.info(\"Computing final interaction strength\")\n",
    "    merged['interaction'] = merged.apply(\n",
    "        lambda row: row['score'] / 10 if row['score'] > 0 else max(row['status_weight'], row['episode_ratio']),\n",
    "        axis=1\n",
    "    )\n",
    "    # For ranking evaluation, copy interaction to 'implicit'\n",
    "    merged['implicit'] = merged['interaction']\n",
    "    nan_count = merged['interaction'].isna().sum()\n",
    "    if nan_count > 0:\n",
    "        logger.error(\"Found %d NaN values in interaction column\", nan_count)\n",
    "    logger.info(\"Preprocessing complete. Merged shape: %s\", merged.shape)\n",
    "    return merged\n",
    "\n",
    "def create_train_test_split(merged, test_size=TRAIN_TEST_SPLIT, random_state=RANDOM_STATE):\n",
    "    logger.info(\"Splitting merged data into train and test sets (test_size=%.2f)\", test_size)\n",
    "    train, test = train_test_split(merged, test_size=test_size, random_state=random_state)\n",
    "    logger.info(\"Train shape: %s; Test shape: %s\", train.shape, test.shape)\n",
    "    return train, test\n",
    "\n",
    "def build_interaction_matrix(train):\n",
    "    logger.info(\"Building interaction matrix from training data\")\n",
    "    # Use np.unique to ensure unique IDs.\n",
    "    user_ids = np.unique(train['user_id'])\n",
    "    anime_ids = np.unique(train['anime_id'])\n",
    "    user2idx = {user: idx for idx, user in enumerate(user_ids)}\n",
    "    anime2idx = {anime: idx for idx, anime in enumerate(anime_ids)}\n",
    "    \n",
    "    logger.info(\"Total users: %d, Total anime: %d\", len(user_ids), len(anime_ids))\n",
    "    \n",
    "    train = train.copy()\n",
    "    train['user_idx'] = train['user_id'].map(user2idx)\n",
    "    train['anime_idx'] = train['anime_id'].map(anime2idx)\n",
    "    \n",
    "    interaction_matrix = coo_matrix(\n",
    "        (train['interaction'], (train['user_idx'], train['anime_idx'])),\n",
    "        shape=(len(user_ids), len(anime_ids))\n",
    "    ).tocsr()\n",
    "    logger.info(\"Interaction matrix shape: %s\", interaction_matrix.shape)\n",
    "    return interaction_matrix, user2idx, anime2idx\n",
    "\n",
    "# --- Model Training ---\n",
    "def train_wrmf_model(interaction_matrix, factors=DEFAULT_FACTORS, reg=DEFAULT_REG, iterations=DEFAULT_ITER):\n",
    "    logger.info(\"Training WRMF model using ALS with factors=%d, reg=%.4f, iterations=%d\", factors, reg, iterations)\n",
    "    model = implicit.als.AlternatingLeastSquares(\n",
    "        factors=factors,\n",
    "        regularization=reg,\n",
    "        iterations=iterations,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    model.fit(interaction_matrix.T)  # Transpose: implicit expects item-user matrix\n",
    "    logger.info(\"WRMF model training complete.\")\n",
    "    return model\n",
    "\n",
    "# --- Pointwise Metrics Evaluation ---\n",
    "def compute_pointwise_metrics(model, test_df, user2idx, anime2idx):\n",
    "    errors = []\n",
    "    abs_errors = []\n",
    "    for _, row in test_df.iterrows():\n",
    "        score = row['score']\n",
    "        if score > 0 and row['user_id'] in user2idx and row['anime_id'] in anime2idx:\n",
    "            u_idx = user2idx[row['user_id']]\n",
    "            a_idx = anime2idx[row['anime_id']]\n",
    "            if u_idx >= model.user_factors.shape[0] or a_idx >= model.item_factors.shape[0]:\n",
    "                logger.warning(\"Skipping row: user %s->%d, anime %s->%d out of bounds\",\n",
    "                               row['user_id'], u_idx, row['anime_id'], a_idx)\n",
    "                continue\n",
    "            pred = np.dot(model.user_factors[u_idx], model.item_factors[a_idx])\n",
    "            errors.append((score - pred) ** 2)\n",
    "            abs_errors.append(abs(score - pred))\n",
    "    if errors:\n",
    "        rmse = np.sqrt(np.mean(errors))\n",
    "        mae = np.mean(abs_errors)\n",
    "    else:\n",
    "        rmse, mae = None, None\n",
    "    return rmse, mae\n",
    "\n",
    "# --- Ranking Metrics Evaluation ---\n",
    "def precision_at_k(recommended, relevant, k=10):\n",
    "    recommended_k = [rec for rec, _ in recommended][:k]\n",
    "    if not recommended_k:\n",
    "        return 0.0\n",
    "    hits = len(set(recommended_k) & relevant)\n",
    "    return hits / k\n",
    "\n",
    "def recall_at_k(recommended, relevant, k=10):\n",
    "    recommended_k = [rec for rec, _ in recommended][:k]\n",
    "    if len(relevant) == 0:\n",
    "        return 0.0\n",
    "    hits = len(set(recommended_k) & relevant)\n",
    "    return hits / len(relevant)\n",
    "\n",
    "def ndcg_at_k(recommended, relevant, k=10):\n",
    "    dcg = 0.0\n",
    "    for i, (rec, _) in enumerate(recommended[:k]):\n",
    "        if rec in relevant:\n",
    "            dcg += 1 / np.log2(i + 2)\n",
    "    ideal_hits = min(len(relevant), k)\n",
    "    idcg = sum(1 / np.log2(i + 2) for i in range(ideal_hits))\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "def compute_ranking_metrics_for_user(user, group, model, user2idx, anime2idx, train_matrix, top_k=TOP_N, relevance_threshold=0.1):\n",
    "    if user not in user2idx:\n",
    "        logger.warning(\"User %s not found in training mapping.\", user)\n",
    "        return None\n",
    "    group = group[group['anime_id'].isin(anime2idx.keys())]\n",
    "    if group.empty:\n",
    "        logger.info(\"No test data for user %s after filtering.\", user)\n",
    "        return None\n",
    "    relevant_items = set(group[group['interaction'] >= relevance_threshold]['anime_id'])\n",
    "    if not relevant_items:\n",
    "        logger.info(\"No relevant items for user %s.\", user)\n",
    "        return None\n",
    "    u_idx = user2idx[user]\n",
    "    train_csr = train_matrix.tocsr()\n",
    "    recommendations = model.recommend(u_idx, train_csr[u_idx], N=top_k, filter_already_liked_items=False)\n",
    "    idx2anime = {idx: anime for anime, idx in anime2idx.items()}\n",
    "    # Unpack only the first two elements from each tuple.\n",
    "    recs = [(idx2anime.get(t[0]), t[1]) for t in recommendations]\n",
    "    prec = precision_at_k(recs, relevant_items, k=top_k)\n",
    "    rec = recall_at_k(recs, relevant_items, k=top_k)\n",
    "    ndcg_val = ndcg_at_k(recs, relevant_items, k=top_k)\n",
    "    return prec, rec, ndcg_val\n",
    "\n",
    "# --- Hyperparameter Tuning Objective Function ---\n",
    "def objective(trial):\n",
    "    factors = trial.suggest_categorical(\"factors\", [50, 100, 150, 200])\n",
    "    reg = trial.suggest_float(\"reg\", 1e-3, 1e-1, log=True)\n",
    "    n_iter = trial.suggest_int(\"n_iter\", 10, 50)\n",
    "    alpha = trial.suggest_categorical(\"alpha\", [20, 40, 60, 80])\n",
    "    \n",
    "    params = {\"factors\": factors, \"reg\": reg, \"n_iter\": n_iter, \"alpha\": alpha}\n",
    "    logger.info(\"Trial parameters: %s\", params)\n",
    "    \n",
    "    key = cache_key(params)\n",
    "    if os.path.exists(cache_path(key)):\n",
    "        logger.info(\"Loading cached results for key: %s\", key)\n",
    "        cached = load_cache_obj(key)\n",
    "        trial.set_user_attr(\"rmse\", cached[\"rmse\"])\n",
    "        trial.set_user_attr(\"mae\", cached[\"mae\"])\n",
    "        trial.set_user_attr(\"precision_at_10\", cached[\"precision_at_10\"])\n",
    "        trial.set_user_attr(\"recall_at_10\", cached[\"recall_at_10\"])\n",
    "        trial.set_user_attr(\"ndcg_at_10\", cached[\"ndcg_at_10\"])\n",
    "        return cached[\"objective\"]\n",
    "    \n",
    "    animelist, anime_details = load_data(ANIMELIST_FILE, ANIME_DETAILS_FILE)\n",
    "    merged = preprocess(animelist, anime_details)\n",
    "    train, test = create_train_test_split(merged)\n",
    "    \n",
    "    train_matrix, user2idx, anime2idx = build_interaction_matrix(train)\n",
    "    \n",
    "    model = implicit.als.AlternatingLeastSquares(\n",
    "        factors=factors,\n",
    "        regularization=reg,\n",
    "        iterations=n_iter,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    model.fit(train_matrix.T)\n",
    "    \n",
    "    rmse, mae = compute_pointwise_metrics(model, test, user2idx, anime2idx)\n",
    "    trial.set_user_attr(\"rmse\", rmse)\n",
    "    trial.set_user_attr(\"mae\", mae)\n",
    "    \n",
    "    test_groups = list(test.groupby('user_id'))\n",
    "    logger.info(\"Number of test groups: %d\", len(test_groups))\n",
    "    sampled_groups = test_groups[:int(len(test_groups) * 0.2)]\n",
    "    \n",
    "    ranking_results = []\n",
    "    for user, group in sampled_groups:\n",
    "        res = compute_ranking_metrics_for_user(user, group, model, user2idx, anime2idx, train_matrix, top_k=TOP_N, relevance_threshold=0.1)\n",
    "        ranking_results.append(res)\n",
    "    valid_results = [res for res in ranking_results if res is not None]\n",
    "    if valid_results:\n",
    "        precisions, recalls, ndcgs = zip(*valid_results)\n",
    "        precision_val = np.mean(precisions)\n",
    "        recall_val = np.mean(recalls)\n",
    "        ndcg_val = np.mean(ndcgs)\n",
    "    else:\n",
    "        precision_val = recall_val = ndcg_val = float('inf')\n",
    "    \n",
    "    trial.set_user_attr(\"precision_at_10\", precision_val)\n",
    "    trial.set_user_attr(\"recall_at_10\", recall_val)\n",
    "    trial.set_user_attr(\"ndcg_at_10\", ndcg_val)\n",
    "    \n",
    "    # Optimize for recall (i.e. minimize 1 - recall)\n",
    "    objective_value = 1 - recall_val\n",
    "    logger.info(\"Trial metrics: RMSE: %s, MAE: %s, Precision@10: %.4f, Recall@10: %.4f, NDCG@10: %.4f, Objective (1 - recall): %.4f\",\n",
    "                rmse, mae, precision_val, recall_val, ndcg_val, objective_value)\n",
    "    \n",
    "    cache_obj = {\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "        \"precision_at_10\": precision_val,\n",
    "        \"recall_at_10\": recall_val,\n",
    "        \"ndcg_at_10\": ndcg_val,\n",
    "        \"objective\": objective_value\n",
    "    }\n",
    "    save_cache_obj(cache_obj, key)\n",
    "    return objective_value\n",
    "\n",
    "def main_experiment():\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=20)\n",
    "    \n",
    "    results = []\n",
    "    for trial in study.trials:\n",
    "        results.append({\n",
    "            \"model_name\": \"WRMF\",\n",
    "            \"rmse\": trial.user_attrs.get(\"rmse\"),\n",
    "            \"mae\": trial.user_attrs.get(\"mae\"),\n",
    "            \"precision_at_10\": trial.user_attrs.get(\"precision_at_10\"),\n",
    "            \"recall_at_10\": trial.user_attrs.get(\"recall_at_10\"),\n",
    "            \"ndcg_at_10\": trial.user_attrs.get(\"ndcg_at_10\"),\n",
    "            \"parameters\": str(trial.params),\n",
    "            \"objective\": trial.value\n",
    "        })\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_csv = \"wrmf_experiment_results.csv\"\n",
    "    results_df.to_csv(results_csv, index=False)\n",
    "    logger.info(\"Saved experiment results to %s\", results_csv)\n",
    "    logger.info(\"Best trial: %s with Objective (1 - recall): %.4f\", study.best_trial.params, study.best_trial.value)\n",
    "    \n",
    "    # Final retraining: use entire merged dataset so that mapping is complete.\n",
    "    animelist, anime_details = load_data(ANIMELIST_FILE, ANIME_DETAILS_FILE)\n",
    "    merged = preprocess(animelist, anime_details)\n",
    "    final_matrix, user2idx, anime2idx = build_interaction_matrix(merged)\n",
    "    logger.info(\"Final training: user count: %d, anime count: %d, matrix shape: %s\",\n",
    "                len(user2idx), len(anime2idx), final_matrix.shape)\n",
    "    \n",
    "    best_params = study.best_trial.params\n",
    "    logger.info(\"Retraining best model with parameters: %s\", best_params)\n",
    "    best_model_obj = implicit.als.AlternatingLeastSquares(\n",
    "        factors=best_params[\"factors\"],\n",
    "        regularization=best_params[\"reg\"],\n",
    "        iterations=best_params[\"n_iter\"],\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    best_model_obj.fit(final_matrix.T)\n",
    "    logger.info(\"Final model training complete. User factors shape: %s, Item factors shape: %s\",\n",
    "                best_model_obj.user_factors.shape, best_model_obj.item_factors.shape)\n",
    "    \n",
    "    final_model = {\n",
    "        \"model\": best_model_obj,\n",
    "        \"interaction_matrix\": final_matrix,\n",
    "        \"user2idx\": user2idx,\n",
    "        \"anime2idx\": anime2idx,\n",
    "        \"merged\": merged\n",
    "    }\n",
    "    with open(MODEL_SAVE_PATH, \"wb\") as f:\n",
    "        pickle.dump(final_model, f)\n",
    "    logger.info(\"Best WRMF model saved to '%s'\", MODEL_SAVE_PATH)\n",
    "    \n",
    "    # New user recommendation: self-contained call.\n",
    "    recommend_new_user()\n",
    "\n",
    "# --- New User Recommendation (Self-contained) ---\n",
    "def recommend_new_user():\n",
    "    import pickle\n",
    "    import logging\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    logger = logging.getLogger()\n",
    "    MODEL_SAVE_PATH = \"models/wrmf_best_model.pkl\"\n",
    "    ANIME_DETAILS_FILE = \"data_new/anime_details_v1.csv\"\n",
    "    NEW_USER_FILE = \"data_new/user_data.csv\"\n",
    "    \n",
    "    logger.info(\"Loading best model from '%s'\", MODEL_SAVE_PATH)\n",
    "    with open(MODEL_SAVE_PATH, \"rb\") as f:\n",
    "        final_model = pickle.load(f)\n",
    "    model = final_model[\"model\"]\n",
    "    anime2idx = final_model[\"anime2idx\"]\n",
    "    \n",
    "    anime_details = pd.read_csv(ANIME_DETAILS_FILE)\n",
    "    anime_details = anime_details.rename(columns={'id': 'anime_id'})\n",
    "    \n",
    "    logger.info(\"Loading new user data from '%s'\", NEW_USER_FILE)\n",
    "    new_user_df = pd.read_csv(NEW_USER_FILE)\n",
    "    \n",
    "    # Build new user vector using saved mapping.\n",
    "    new_user_vector = np.zeros(len(anime2idx), dtype=np.float32)\n",
    "    for anime in new_user_df['anime_id'].unique():\n",
    "        if anime in anime2idx:\n",
    "            score = new_user_df[new_user_df['anime_id'] == anime]['score'].values[0]\n",
    "            new_user_vector[anime2idx[anime]] = score / 10 if score > 0 else 1\n",
    "    logger.info(\"New user vector built with shape: %s\", new_user_vector.shape)\n",
    "    \n",
    "    def fold_in_new_user(new_user_vector, item_factors, learning_rate=0.005, reg=0.02, n_iter=50):\n",
    "        n_factors = item_factors.shape[1]\n",
    "        u_new = np.random.normal(scale=0.1, size=(n_factors,))\n",
    "        observed = new_user_vector > 0\n",
    "        # Check that observed mask length matches item_factors rows.\n",
    "        if observed.shape[0] != item_factors.shape[0]:\n",
    "            logger.error(\"Mismatch: new_user_vector length %d does not match item_factors rows %d\",\n",
    "                         observed.shape[0], item_factors.shape[0])\n",
    "            # Clip the boolean mask to correct length.\n",
    "            observed = observed[:item_factors.shape[0]]\n",
    "        for _ in range(n_iter):\n",
    "            pred = item_factors[observed].dot(u_new)\n",
    "            error = new_user_vector[observed] - pred\n",
    "            grad = -2 * item_factors[observed].T.dot(error) + 2 * reg * u_new\n",
    "            u_new = u_new - learning_rate * grad\n",
    "        return u_new\n",
    "\n",
    "    u_new = fold_in_new_user(new_user_vector, model.item_factors)\n",
    "    predictions = {}\n",
    "    for anime, idx in anime2idx.items():\n",
    "        if idx >= model.item_factors.shape[0]:\n",
    "            logger.warning(\"Skipping anime %s with index %d (out-of-bounds)\", anime, idx)\n",
    "            continue\n",
    "        if new_user_vector[idx] == 0:\n",
    "            predictions[anime] = np.dot(u_new, model.item_factors[idx])\n",
    "    top_recs = sorted(predictions.items(), key=lambda x: x[1], reverse=True)[:TOP_N]\n",
    "    recs_df = pd.DataFrame(top_recs, columns=[\"anime_id\", \"predicted_rating\"])\n",
    "    enriched = pd.merge(recs_df, anime_details, left_on=\"anime_id\", right_on=\"anime_id\", how=\"left\")\n",
    "    logger.info(\"New user recommendations computed:\")\n",
    "    logger.info(\"\\n%s\", enriched.to_string(index=False))\n",
    "    return enriched\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "main_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# Set up logging for realtime output\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s: %(message)s')\n",
    "\n",
    "def load_data(animelist_path, anime_details_path):\n",
    "    logging.info(\"Loading animelist data from '%s'\", animelist_path)\n",
    "    animelist = pd.read_csv(animelist_path)\n",
    "    \n",
    "    logging.info(\"Loading anime details from '%s'\", anime_details_path)\n",
    "    anime_details = pd.read_csv(anime_details_path)\n",
    "    \n",
    "    return animelist, anime_details\n",
    "\n",
    "def preprocess(animelist, anime_details):\n",
    "    logging.info(\"Filling missing scores with 0\")\n",
    "    animelist['score'] = animelist['score'].fillna(0)\n",
    "    \n",
    "    # Optionally normalize the status string (e.g., lowercase)\n",
    "    animelist['status'] = animelist['status'].str.lower()\n",
    "    \n",
    "    # Update the mapping to include additional statuses if needed.\n",
    "    status_mapping = {\n",
    "        'completed': 1.0,\n",
    "        'on_hold': 0.5,\n",
    "        'plan_to_watch': 0.2,\n",
    "        'dropped': 0.0,\n",
    "        # For statuses not explicitly defined, we could assign a default weight.\n",
    "        'watching': 0.8,    # example weight for watching\n",
    "        'rewatching': 0.9   # example weight for rewatching\n",
    "    }\n",
    "    logging.info(\"Mapping status to weights using: %s\", status_mapping)\n",
    "    animelist['status_weight'] = animelist['status'].map(status_mapping)\n",
    "    \n",
    "    # Fill any missing status weights with a default value (e.g., 0)\n",
    "    missing_weights = animelist['status_weight'].isna().sum()\n",
    "    if missing_weights > 0:\n",
    "        logging.warning(\"Found %d missing status weights, filling with default 0\", missing_weights)\n",
    "        animelist['status_weight'] = animelist['status_weight'].fillna(0)\n",
    "    \n",
    "    # Merge to get total episodes from anime_details.\n",
    "    logging.info(\"Renaming anime details column 'id' to 'anime_id' for merge\")\n",
    "    anime_details = anime_details.rename(columns={'id': 'anime_id'})\n",
    "    \n",
    "    logging.info(\"Merging animelist with anime_details to add total episodes info\")\n",
    "    merged = pd.merge(animelist, anime_details[['anime_id', 'num_episodes']], on='anime_id', how='left')\n",
    "    \n",
    "    # Avoid division errors: if total episodes is missing, fill with 1.\n",
    "    merged['num_episodes'] = merged['num_episodes'].fillna(1)\n",
    "    \n",
    "    # Compute ratio of episodes watched (capped at 1)\n",
    "    logging.info(\"Computing episode ratio as num_episodes_watched / num_episodes\")\n",
    "    merged['episode_ratio'] = (merged['num_episodes_watched'] / merged['num_episodes']).clip(upper=1)\n",
    "    \n",
    "    # Compute final interaction strength.\n",
    "    # If a score is provided (> 0), we use normalized score (assuming scores are out of 10).\n",
    "    # Otherwise, use the maximum between the status weight and episode_ratio.\n",
    "    logging.info(\"Computing final interaction strength\")\n",
    "    merged['interaction'] = merged.apply(\n",
    "        lambda row: row['score'] / 10 if row['score'] > 0 \n",
    "                    else max(row['status_weight'], row['episode_ratio']),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Check if any NaN values still exist in the interaction column\n",
    "    nan_count = merged['interaction'].isna().sum()\n",
    "    if nan_count > 0:\n",
    "        logging.error(\"There are %d NaN values in the interaction column\", nan_count)\n",
    "    \n",
    "    return merged\n",
    "\n",
    "def create_train_test_split(merged, test_size=0.2, random_state=42):\n",
    "    logging.info(\"Splitting data into train and test sets with test size = %.2f\", test_size)\n",
    "    train, test = train_test_split(merged, test_size=test_size, random_state=random_state)\n",
    "    return train, test\n",
    "\n",
    "def build_interaction_matrix(train):\n",
    "    logging.info(\"Building interaction matrix from training data\")\n",
    "    # Create mappings for user and anime IDs\n",
    "    user_ids = train['user_id'].unique()\n",
    "    anime_ids = train['anime_id'].unique()\n",
    "    user2idx = {user: idx for idx, user in enumerate(user_ids)}\n",
    "    anime2idx = {anime: idx for idx, anime in enumerate(anime_ids)}\n",
    "    \n",
    "    # Map user_id and anime_id to indices\n",
    "    train = train.copy()  # avoid SettingWithCopyWarning\n",
    "    train['user_idx'] = train['user_id'].map(user2idx)\n",
    "    train['anime_idx'] = train['anime_id'].map(anime2idx)\n",
    "    \n",
    "    # Build the sparse matrix\n",
    "    interaction_matrix = coo_matrix(\n",
    "        (train['interaction'], (train['user_idx'], train['anime_idx'])),\n",
    "        shape=(len(user_ids), len(anime_ids))\n",
    "    )\n",
    "    \n",
    "    logging.info(\"Interaction matrix shape: %s\", interaction_matrix.shape)\n",
    "    return interaction_matrix, user2idx, anime2idx\n",
    "\n",
    "def train_model(interaction_matrix):\n",
    "    logging.info(\"Training implicit feedback model using default hyper parameters\")\n",
    "    try:\n",
    "        import implicit\n",
    "    except ImportError:\n",
    "        logging.error(\"The 'implicit' library is not installed. Please install it via pip install implicit\")\n",
    "        raise\n",
    "\n",
    "    # Use ALS model from the implicit library.\n",
    "    # Note: implicit expects an item-user matrix so we transpose.\n",
    "    model = implicit.als.AlternatingLeastSquares(\n",
    "        factors=50,          # number of latent factors\n",
    "        regularization=0.01,   # regularization term\n",
    "        iterations=10         # number of iterations for training\n",
    "    )\n",
    "    logging.info(\"Fitting model (this may take a moment)...\")\n",
    "    model.fit(interaction_matrix.T)\n",
    "    logging.info(\"Model training complete\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, test, user2idx, anime2idx, train_matrix, top_k=10):\n",
    "    logging.info(\"Evaluating model performance using Recall@%d\", top_k)\n",
    "    hit_count = 0\n",
    "    total_count = 0\n",
    "\n",
    "    # Ensure the training matrix is in CSR format for fast row slicing.\n",
    "    train_csr = train_matrix.tocsr()\n",
    "\n",
    "    # For each user in the test set:\n",
    "    for user in test['user_id'].unique():\n",
    "        if user not in user2idx:\n",
    "            continue  # skip users not in the training set\n",
    "        user_index = user2idx[user]\n",
    "        # Get test anime ids for this user\n",
    "        test_anime = test[test['user_id'] == user]['anime_id'].unique()\n",
    "        \n",
    "        # Get recommendations for the user.\n",
    "        # Here we are not filtering out items already seen, but you can adjust that.\n",
    "        recommended = model.recommend(\n",
    "            user_index, train_csr[user_index], N=top_k, filter_already_liked_items=False\n",
    "        )\n",
    "        # recommended is a list of tuples (anime_idx, score)\n",
    "        recommended_anime_idxs = [rec[0] for rec in recommended]\n",
    "        # Map indices back to anime_id\n",
    "        # (Since anime2idx is a dict, we invert it here)\n",
    "        idx2anime = {idx: anime for anime, idx in anime2idx.items()}\n",
    "        recommended_anime_ids = [idx2anime.get(idx) for idx in recommended_anime_idxs]\n",
    "        \n",
    "        hits = len(set(test_anime) & set(recommended_anime_ids))\n",
    "        hit_count += hits\n",
    "        total_count += len(test_anime)\n",
    "    \n",
    "    recall = hit_count / total_count if total_count > 0 else 0\n",
    "    logging.info(\"Recall@%d: %.4f\", top_k, recall)\n",
    "    return recall\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Paths to your CSV files (adjust if necessary)\n",
    "    animelist_path = \"data_new/animelist.csv\"\n",
    "    anime_details_path = \"data_new/anime_details_v1.csv\"  # using the provided filename\n",
    "\n",
    "    # Load data\n",
    "    animelist, anime_details = load_data(animelist_path, anime_details_path)\n",
    "    \n",
    "    # Preprocess data\n",
    "    merged_data = preprocess(animelist, anime_details)\n",
    "    \n",
    "    # Split data\n",
    "    train_data, test_data = create_train_test_split(merged_data)\n",
    "    \n",
    "    # Build the interaction matrix for the training set\n",
    "    interaction_matrix, user2idx, anime2idx = build_interaction_matrix(train_data)\n",
    "    \n",
    "    # Train the implicit model\n",
    "    model = train_model(interaction_matrix)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    recall = evaluate_model(model, test_data, user2idx, anime2idx, interaction_matrix, top_k=10)\n",
    "    \n",
    "    logging.info(\"Recommendation system training and evaluation complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to your CSV files (adjust if necessary)\n",
    "animelist_path = \"data_new/animelist.csv\"\n",
    "anime_details_path = \"data_new/anime_details_v1.csv\"  # using the provided filename\n",
    "\n",
    "# Load data\n",
    "animelist, anime_details = load_data(animelist_path, anime_details_path)\n",
    "\n",
    "# Preprocess data\n",
    "merged_data = preprocess(animelist, anime_details)\n",
    "\n",
    "# Split data\n",
    "train_data, test_data = create_train_test_split(merged_data)\n",
    "\n",
    "# Build the interaction matrix for the training set\n",
    "interaction_matrix, user2idx, anime2idx = build_interaction_matrix(train_data)\n",
    "\n",
    "# Train the implicit model\n",
    "model = train_model(interaction_matrix)\n",
    "\n",
    "# Evaluate the model\n",
    "recall = evaluate_model(model, test_data, user2idx, anime2idx, interaction_matrix, top_k=10)\n",
    "\n",
    "logging.info(\"Recommendation system training and evaluation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item - item collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_1 = pd.read_csv('data_new/anime_details_v1.csv')\n",
    "df_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import pickle\n",
    "import ast\n",
    "\n",
    "# Load and preprocess data\n",
    "anime_metadata = pd.read_csv('data_new/anime_details_v1.csv')\n",
    "\n",
    "# Define features\n",
    "text_features = ['synopsis', 'genres']\n",
    "categorical_features = ['studios', 'media_type', 'source']\n",
    "numerical_features = ['start_year', 'mean', 'rank', 'popularity', 'num_episodes']\n",
    "\n",
    "# Convert JSON strings to lists\n",
    "def safe_literal_eval(val):\n",
    "    try:\n",
    "        return [d['name'] for d in ast.literal_eval(val)] if pd.notnull(val) else []\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []\n",
    "\n",
    "anime_metadata['genres'] = anime_metadata['genres'].apply(safe_literal_eval)\n",
    "anime_metadata['studios'] = anime_metadata['studios'].apply(safe_literal_eval)\n",
    "anime_metadata['synopsis'] = anime_metadata['synopsis'].fillna('').astype(str)\n",
    "print('Finished preprocessing data')\n",
    "\n",
    "\n",
    "anime_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix for the preprocessor definition\n",
    "def extract_genres(df):\n",
    "    return df['genres']\n",
    "def extract_studios(df):\n",
    "    return df['studios']\n",
    "def safe_multilabel_binarize(x):\n",
    "    return MultiLabelBinarizer().fit_transform(x)\n",
    "def extract_synopsis(df):\n",
    "    return df[['synopsis']]\n",
    "def safe_tostring(x):\n",
    "    return [str(item[0]) for item in x]\n",
    "def preprocessor_for_genres(x):\n",
    "    return ' '.join(x) if isinstance(x, list) else ''\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "         ('genres', Pipeline([\n",
    "            ('selector', FunctionTransformer(extract_genres, validate=False)),\n",
    "            ('genre_clean', TfidfVectorizer(\n",
    "                preprocessor=preprocessor_for_genres,\n",
    "                token_pattern=r'(?u)\\b[\\w-]+\\b',\n",
    "                min_df=2\n",
    "            )),\n",
    "        ]), ['genres']),\n",
    "        \n",
    "        # For synopsis\n",
    "        ('synopsis_tfidf', Pipeline([\n",
    "            ('selector', FunctionTransformer(extract_synopsis, validate=False)),\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='')),\n",
    "            ('to_string', FunctionTransformer(safe_tostring, validate=False)),\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                stop_words='english',\n",
    "                min_df=2,\n",
    "                max_features=5000\n",
    "            ))\n",
    "        ]), ['synopsis']),\n",
    "        \n",
    "        # For numerical features (already a 2D selection)\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', MinMaxScaler())\n",
    "        ]), numerical_features),\n",
    "        \n",
    "        # For studios (list column)\n",
    "        ('studios_mlb', Pipeline([\n",
    "            # This ensures we pass a 2D array to the MultiLabelBinarizer\n",
    "            ('selector', FunctionTransformer(extract_studios, validate=False)),\n",
    "            ('mlb', FunctionTransformer(safe_multilabel_binarize))\n",
    "        ]), ['studios']),\n",
    "        \n",
    "        # For other categorical features\n",
    "        ('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), ['media_type', 'source'])\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "print('created preprocessor')\n",
    "# Execute pipeline\n",
    "feature_matrix = preprocessor.fit_transform(anime_metadata)\n",
    "print('Finished feature extraction')\n",
    "feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Finished feature extraction')\n",
    "\n",
    "# Compute similarity\n",
    "cosine_sim = linear_kernel(feature_matrix, feature_matrix)\n",
    "print('Computed cosine similarity matrix')\n",
    "# Save model\n",
    "model_artifacts = {\n",
    "    'preprocessor': preprocessor,\n",
    "    'cosine_sim': cosine_sim,\n",
    "    'feature_matrix': feature_matrix,\n",
    "    'metadata': anime_metadata\n",
    "}\n",
    "\n",
    "with open('models/content_based_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model_artifacts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_metadata[anime_metadata['anime_id'] == 38691].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_recommendations(anime_id, n=10):\n",
    "    idx = anime_metadata[anime_metadata['anime_id'] == anime_id].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:n+1]\n",
    "    anime_indices = [i[0] for i in sim_scores]\n",
    "    return anime_metadata.iloc[anime_indices]\n",
    "\n",
    "def load_content_model(path='content_based_model.pkl'):\n",
    "    with open(path, 'rb') as f:\n",
    "        artifacts = pickle.load(f)\n",
    "    return artifacts\n",
    "\n",
    "get_content_recommendations(235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from hyperopt import fmin, tpe, hp, Trials\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from functools import partial\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Fix for the preprocessor definition\n",
    "def extract_genres(df):\n",
    "    return df['genres']\n",
    "def extract_studios(df):\n",
    "    return df['studios']\n",
    "def safe_multilabel_binarize(x):\n",
    "    return MultiLabelBinarizer().fit_transform(x)\n",
    "def extract_synopsis(df):\n",
    "    return df[['synopsis']]\n",
    "def safe_tostring(x):\n",
    "    return [str(item[0]) for item in x]\n",
    "def preprocessor_for_genres(x):\n",
    "    return ' '.join(x) if isinstance(x, list) else ''\n",
    "# 1. Load data and prepare evaluation\n",
    "\n",
    "ratings = pd.read_csv('data_new/animelist_v1.csv')\n",
    "anime_metadata = pd.read_csv('data_new/anime_details_v1.csv')\n",
    "\n",
    "# Convert JSON strings to lists\n",
    "import ast\n",
    "def safe_literal_eval(val):\n",
    "    try:\n",
    "        return [d['name'] for d in ast.literal_eval(val)] if pd.notnull(val) else []\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []\n",
    "\n",
    "anime_metadata['genres'] = anime_metadata['genres'].apply(safe_literal_eval)\n",
    "anime_metadata['studios'] = anime_metadata['studios'].apply(safe_literal_eval)\n",
    "anime_metadata['synopsis'] = anime_metadata['synopsis'].fillna('').astype(str)\n",
    "anime_metadata.rename(columns={'id': 'anime_id'}, inplace=True)\n",
    "\n",
    "# Create user profiles (average rating weighted anime features)\n",
    "user_profiles = ratings.groupby('user_id').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'mean_rating': x['score'].mean(),\n",
    "        'liked_genres': x.merge(anime_metadata, on='anime_id')['genres'].explode().value_counts().to_dict(),\n",
    "        'liked_anime': list(x['anime_id'])\n",
    "    })\n",
    ")\n",
    "\n",
    "# Split into train/test\n",
    "train_users, test_users = train_test_split(user_profiles, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_users.shape, test_users.shape, user_profiles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load precomputed features\n",
    "with open('models/content_based_model.pkl', 'rb') as f:\n",
    "    content_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define parameter space\n",
    "param_space = {\n",
    "    'genre_weight': hp.uniform('genre_weight', 0.1, 2),\n",
    "    'synopsis_weight': hp.uniform('synopsis_weight', 0.1, 2),\n",
    "    'numerical_weight': hp.uniform('numerical_weight', 0.1, 2),\n",
    "    'studio_weight': hp.uniform('studio_weight', 0.1, 2),\n",
    "    'categorical_weight': hp.uniform('categorical_weight', 0.1, 2),\n",
    "    'popularity_decay': hp.uniform('popularity_decay', 0.8, 1),\n",
    "    'age_decay_base': hp.uniform('age_decay_base', 0.9, 0.99),\n",
    "    'genre_boost_factor': hp.uniform('genre_boost_factor', 1, 3),\n",
    "    'min_similarity_threshold': hp.uniform('min_similarity_threshold', 0.1, 1)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features\n",
    "text_features = ['synopsis', 'genres']\n",
    "categorical_features = ['studios', 'media_type', 'source']\n",
    "numerical_features = ['start_year', 'mean', 'rank', 'popularity', 'num_episodes']\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Genres (TF-IDF)\n",
    "genres_pipe = content_data['preprocessor'].named_transformers_['genres']\n",
    "tfidf_genres = genres_pipe.named_steps['genre_clean']\n",
    "num_genres = len(tfidf_genres.get_feature_names_out())\n",
    "\n",
    "# Synopsis (TF-IDF)\n",
    "synopsis_pipe = content_data['preprocessor'].named_transformers_['synopsis_tfidf']\n",
    "tfidf_synopsis = synopsis_pipe.named_steps['tfidf']\n",
    "num_synopsis = len(tfidf_synopsis.get_feature_names_out())\n",
    "\n",
    "# Numerical Features (count matches input)\n",
    "num_num = len(numerical_features)  # Assuming `numerical_features` is a list\n",
    "\n",
    "# Studios (MultiLabelBinarizer output shape)\n",
    "studio_pipe = content_data['preprocessor'].named_transformers_['studios_mlb']\n",
    "studio_sample = studio_pipe.transform(anime_metadata.head(1))\n",
    "num_studios = studio_sample.shape[1]\n",
    "\n",
    "# Categorical (OneHotEncoder)\n",
    "cat_pipe = content_data['preprocessor'].named_transformers_['cat']\n",
    "onehot = cat_pipe.named_steps['onehot']\n",
    "num_cat = len(onehot.get_feature_names_out(['media_type', 'source']))\n",
    "\n",
    "\n",
    "start_genres = 0\n",
    "end_genres = num_genres\n",
    "\n",
    "start_synopsis = end_genres\n",
    "end_synopsis = start_synopsis + num_synopsis\n",
    "\n",
    "start_num = end_synopsis\n",
    "end_num = start_num + num_num\n",
    "\n",
    "start_studios = end_num\n",
    "end_studios = start_studios + num_studios\n",
    "\n",
    "start_cat = end_studios\n",
    "end_cat = start_cat + num_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = content_data['feature_matrix']\n",
    "\n",
    "genres_features = feature_matrix[:, start_genres:end_genres]\n",
    "synopsis_features = feature_matrix[:, start_synopsis:end_synopsis]\n",
    "numerical_features = feature_matrix[:, start_num:end_num]\n",
    "studio_features = feature_matrix[:, start_studios:end_studios]\n",
    "categorical_features = feature_matrix[:, start_cat:end_cat]\n",
    "print(type(genres_features), type(synopsis_features), type(numerical_features), type(studio_features), type(categorical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define objective function\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_genre_boost(anime_row, params):\n",
    "    boost = 1.0\n",
    "    for genre in anime_row['genres']:\n",
    "        boost *= params['genre_boost_factor']\n",
    "    return boost\n",
    "\n",
    "def objective(params, train, test, anime_metadata, genres_features, studio_features, numerical_features, categorical_features, synopsis_features):\n",
    "    from scipy.sparse import hstack\n",
    "    # Apply popularity decay\n",
    "    current_year = pd.Timestamp.now().year\n",
    "    anime_metadata['decayed_popularity'] = anime_metadata['popularity'] * (\n",
    "        params['popularity_decay'] ** (current_year - anime_metadata['start_year'])\n",
    "    )\n",
    "    \n",
    "    # Apply genre boosting\n",
    "    genre_weights = {}\n",
    "    all_genres = []\n",
    "    for genres_list in anime_metadata['genres']:\n",
    "        if isinstance(genres_list, list):\n",
    "            all_genres.extend(genres_list)\n",
    "    unique_genres = set(all_genres)\n",
    "    for genre in unique_genres:\n",
    "        genre_weights[genre] = params['genre_boost_factor']\n",
    "    \n",
    "    # Recalculate similarities with weights\n",
    "    weighted_features = hstack([\n",
    "            genres_features.multiply(params['genre_weight']),\n",
    "            studio_features.multiply(params['studio_weight']),\n",
    "            synopsis_features.multiply(params['synopsis_weight']),\n",
    "            numerical_features.multiply(params['numerical_weight']),\n",
    "            categorical_features.multiply(params['categorical_weight'])\n",
    "    ])\n",
    "    \n",
    "    # Update similarity matrix\n",
    "    cosine_sim = linear_kernel(weighted_features, weighted_features)\n",
    "    \n",
    "     # --- Parallel Processing Setup ---\n",
    "    def process_user(user_id):\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            train_items = train[train['user_id'] == user_id]['anime_id'].values\n",
    "            test_items = test[test['user_id'] == user_id]['anime_id'].values\n",
    "            \n",
    "            # Aggregate recommendations with scores\n",
    "            recommendation_pool = {}\n",
    "            user_df = train[train['user_id'] == user_id]\n",
    "            user_mean = user_df['score'].mean()\n",
    "            for anime_id in train_items:\n",
    "                try: \n",
    "                    if user_df[user_df['anime_id'] == anime_id]['score'].values[0] > user_mean: \n",
    "                        idx = anime_metadata[anime_metadata['anime_id'] == anime_id].index[0]\n",
    "                        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "                        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:51]\n",
    "                        for i, score in sim_scores:\n",
    "                            if i not in recommendation_pool:\n",
    "                                recommendation_pool[i] = score \n",
    "                            else:\n",
    "                                recommendation_pool[i] += score \n",
    "                except KeyError as e:\n",
    "                    print(f\"Skipping invalid anime ID: {anime_id}\")\n",
    "                    raise e\n",
    "            \n",
    "            # Get top 10 recommendations\n",
    "            top_recs = sorted(recommendation_pool.items(), key=lambda x: -x[1])[:50]\n",
    "            top_ids = [x[0] for x in top_recs]\n",
    "            \n",
    "            # Calculate precision\n",
    "            hits = len(set(top_ids).intersection(test_items))\n",
    "            k_recall = min(len(test_items), 10)\n",
    "            print(f\"User {user_id}: Hits: {hits}, Recall@10: {hits / k_recall}\")\n",
    "            return hits / k_recall if top_ids else 0\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing user {user_id}: {e}\")\n",
    "            raise e\n",
    "            # return 0\n",
    "\n",
    "    # --- Parallel Execution ---\n",
    "    test_users = test['user_id'].unique()\n",
    "    scores = Parallel(n_jobs=-1, prefer=\"threads\")(\n",
    "        delayed(process_user)(user_id) \n",
    "        for user_id in test_users\n",
    "    )\n",
    "    \n",
    "    # Return negative mean precision for minimization\n",
    "    return -np.mean(scores)\n",
    "\n",
    "\n",
    "df = pd.read_csv('data_new/animelist_v1.csv')\n",
    "user_count = df['user_id'].value_counts()\n",
    "active_users = user_count[user_count >= 50].index\n",
    "df_filtered = df[df['user_id'].isin(active_users)]\n",
    "train, test = [], []\n",
    "grouped = df_filtered.groupby('user_id')\n",
    "train_test = grouped.apply(lambda x: train_test_split(x, test_size=0.2, random_state=42))\n",
    "train_df = pd.concat([tt[0] for tt in train_test])\n",
    "test_df = pd.concat([tt[1] for tt in train_test])\n",
    "\n",
    "# 4. Optimization setup\n",
    "objective_partial = partial(\n",
    "    objective,\n",
    "    # eval_users=train_users.sample(min(100, len(train_users))),\n",
    "    train = train_df,\n",
    "    test = test_df,\n",
    "    anime_metadata=anime_metadata,\n",
    "    genres_features=genres_features,\n",
    "    studio_features=studio_features,   \n",
    "    synopsis_features=synopsis_features,\n",
    "    numerical_features=numerical_features,\n",
    "    categorical_features=categorical_features\n",
    ")\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(\n",
    "    fn=objective_partial,\n",
    "    space=param_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=100,\n",
    "    trials=trials,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 5. Train final model with best params\n",
    "final_model = {\n",
    "    'params': best,\n",
    "    'cosine_sim': calculate_final_similarity(best, anime_metadata, studio_features, synopsis_features, numerical_features, categorical_features),\n",
    "    'genre_weights': calculate_genre_weights(best, anime_metadata)\n",
    "}\n",
    "\n",
    "# 6. Evaluation functions\n",
    "def calculate_final_similarity(params, anime_metadata, studio_features, synopsis_features, numerical_features, categorical_features):\n",
    "    # Apply popularity decay\n",
    "    from scipy.sparse import hstack\n",
    "    current_year = pd.Timestamp.now().year\n",
    "    anime_metadata['decayed_popularity'] = anime_metadata['popularity'] * (\n",
    "        params['popularity_decay'] ** (current_year - anime_metadata['start_year'])\n",
    "    )\n",
    "    \n",
    "    # Recalculate similarities with weights\n",
    "    weighted_features = hstack([\n",
    "            genres_features.multiply(params['genre_weight']),\n",
    "            studio_features.multiply(params['studio_weight']),\n",
    "            synopsis_features.multiply(params['synopsis_weight']),\n",
    "            numerical_features.multiply(params['numerical_weight']),\n",
    "            categorical_features.multiply(params['categorical_weight'])\n",
    "    ])\n",
    "    \n",
    "    # Update similarity matrix\n",
    "    weighted_cosine_sim = linear_kernel(weighted_features, weighted_features)\n",
    "    return weighted_cosine_sim\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Evaluation functions\n",
    "def calculate_final_similarity(params, anime_metadata, studio_features, synopsis_features, numerical_features, categorical_features):\n",
    "    # Apply popularity decay\n",
    "    from scipy.sparse import hstack\n",
    "    current_year = pd.Timestamp.now().year\n",
    "    anime_metadata['decayed_popularity'] = anime_metadata['popularity'] * (\n",
    "        params['popularity_decay'] ** (current_year - anime_metadata['start_year'])\n",
    "    )\n",
    "    \n",
    "    # Recalculate similarities with weights\n",
    "    weighted_features = hstack([\n",
    "            genres_features.multiply(params['genre_weight']),\n",
    "            studio_features.multiply(params['studio_weight']),\n",
    "            synopsis_features.multiply(params['synopsis_weight']),\n",
    "            numerical_features.multiply(params['numerical_weight']),\n",
    "            categorical_features.multiply(params['categorical_weight'])\n",
    "    ])\n",
    "    \n",
    "    # Update similarity matrix\n",
    "    weighted_cosine_sim = linear_kernel(weighted_features, weighted_features)\n",
    "    return weighted_cosine_sim\n",
    "\n",
    "def calculate_genre_weights(params, anime_metadata):\n",
    "    genre_weights = {}\n",
    "    all_genres = []\n",
    "    for genres_list in anime_metadata['genres']:\n",
    "        if isinstance(genres_list, list):\n",
    "            all_genres.extend(genres_list)\n",
    "    unique_genres = set(all_genres)\n",
    "    for genre in unique_genres:\n",
    "        genre_weights[genre] = params['genre_boost_factor']\n",
    "    return genre_weights\n",
    "\n",
    "\n",
    "    \n",
    "def get_content_recommendations(anime_id, cosine_sim, anime_metadata, genre_weights, min_similarity_threshold, n=10):\n",
    "    # Get the index of the anime\n",
    "    idx = anime_metadata[anime_metadata['anime_id'] == anime_id].index[0]\n",
    "\n",
    "    # Get the pairwise similarity scores\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the anime based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the 10 most similar anime\n",
    "    sim_scores = sim_scores[1:n+1]\n",
    "\n",
    "    # Get the anime indices\n",
    "    anime_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Filter by minimum similarity threshold\n",
    "    filtered_indices = [i for i, score in enumerate(sim_scores) if score[1] >= min_similarity_threshold * 10]\n",
    "    anime_indices = [anime_indices[i] for i in filtered_indices]\n",
    "\n",
    "    # Return the top 10 most similar anime\n",
    "    recommendations = anime_metadata.iloc[anime_indices][['anime_id', 'title', 'synopsis', 'mean', 'popularity', 'genres']].to_dict('records')\n",
    "    \n",
    "    # Apply genre boosting\n",
    "    for rec in recommendations:\n",
    "        boost = 1.0\n",
    "        for genre in rec['genres']:\n",
    "            if genre in genre_weights:\n",
    "                boost *= genre_weights[genre]\n",
    "        rec['score'] = rec['mean'] * boost\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Verification\n",
    "test_precision = objective(best, test_users.sample(min(50, len(test_users))), anime_metadata, studio_features, numerical_features, categorical_features, synopsis_features)\n",
    "print(f\"Final test precision@10: {-test_precision:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best['min_similarity_threshold'] = best['min_sim']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model['params'] = best\n",
    "with open('models/optimized_content_model.pkl', 'wb') as f:\n",
    "    pickle.dump(final_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('data_new/animelist_v1.csv')\n",
    "user_count = df['user_id'].value_counts()\n",
    "active_users = user_count[user_count >= 10].index\n",
    "df_filtered = df[df['user_id'].isin(active_users)]\n",
    "train, test = [], []\n",
    "grouped = df_filtered.groupby('user_id')\n",
    "train_test = grouped.apply(lambda x: train_test_split(x, test_size=0.2, random_state=42))\n",
    "train_df = pd.concat([tt[0] for tt in train_test])\n",
    "test_df = pd.concat([tt[1] for tt in train_test])\n",
    "train_df.to_csv('data_new/train_data.csv', index=False)\n",
    "test_df.to_csv('data_new/test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_new/animelist_v1.csv')\n",
    "user_count = df['user_id'].value_counts()\n",
    "active_users = user_count[user_count >= 50].index\n",
    "df_filtered = df[df['user_id'].isin(active_users)]\n",
    "train, test = [], []\n",
    "grouped = df_filtered.groupby('user_id')\n",
    "train_test = grouped.apply(lambda x: train_test_split(x, test_size=0.2, random_state=42))\n",
    "train_df = pd.concat([tt[0] for tt in train_test])\n",
    "test_df = pd.concat([tt[1] for tt in train_test])\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/optimized_content_model.pkl', 'rb') as f:\n",
    "    content_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_items = train_df[train_df['user_id'] == 'kudacukiii']['anime_id'].values\n",
    "test_items = test_df[test_df['user_id'] == 'kudacukiii']['anime_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train_df[train_df['user_id'] == 'kudacukiii']\n",
    "for anime in train_items:\n",
    "    print(temp[temp['anime_id'] == anime]['score'].values[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_pool = {}\n",
    "for anime_id in train_items:\n",
    "    try: \n",
    "        idx = anime_metadata[anime_metadata['anime_id'] == anime_id].index[0]\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:1000]\n",
    "        for i, score in sim_scores:\n",
    "            if i not in recommendation_pool:\n",
    "                recommendation_pool[i] = score\n",
    "            else:\n",
    "                recommendation_pool[i] += score\n",
    "    except KeyError as e:\n",
    "        print(f\"Skipping invalid anime ID: {anime_id}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 10 recommendations\n",
    "top_recs = sorted(recommendation_pool.items(), key=lambda x: -x[1])[:1000]\n",
    "top_ids = [x[0] for x in top_recs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(top_ids).intersection(test_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_metadata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
